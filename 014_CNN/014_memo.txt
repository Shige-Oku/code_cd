
MNISTデータセット + Kerasを使ってCNNを構築
　・コンピュータービジョンとは「人間が行うのと同じ方法でコンピューターが画像を見たり、識別したり、処理することを可能にするコンピューターサイエンスの分野」
　・コンピュータービジョンを活用した一つの事例として、画像分類問題がある。
　・MNISTデータセット
　　・「MNIST（エムニスト）」
　　・0から9までの70,000個の手書き数字の画像から構成されている。
　　【24個掲載】機械学習で使えるデータセット一挙勢揃い！
　　https://www.codexa.net/ml-dataset-list/
　・画像データ
　　・「高さ x 幅 x チャンネル」の行列形式
　　・画像には1チャンネルまたは3チャンネルがある。
　　・3チャンネルとは「赤」「緑」「青」の各色情報。RGBカラー。
　　・ピクセルの値は0-255のレンジ。
　・ニューラルネットと畳み込みニューラルネットワーク
　　・CNN（Convolutional Neural Network - 畳み込みニューラルネットワーク）。
　　・ニューラルネットワークとは、「人間の脳の構造を模したコンピューターシステム」。
　　・CNNは画像認識及び分類において極めて良好に機能するニューラルネットワーク。
　・Keras（ケラス）
　　・KerasはPythonで描かれたディープラーニングラリブラリ・
　　・TensorFlow（テンソルフロー）やTheano（テアノ）の上で実行可能な高水準のニューラルネットワークAPI。
　　・非常に簡単かつ高速にニューラルネットワークを構築することが可能。
　　
　・X_train = X_train.astype('float32')：データタイプ変換
　・y_train = np_utils.to_categorical(y_train, 10)：カテゴリカル変数に変換（one-hot）
　
　・model = Sequential()：モデルの生成
　・model.add()：レイヤーの追加
　・model.compile()：コンパイル。どのような学習処理を行うか設定する。
　・model.fit(X_train, y_train, epochs=10)：モデルの訓練
　・loss_and_metrics = model.evaluate(X_test, y_test, batch_size=128)：モデルの評価
　・predictions = model.predict_classes(X_test)：予測
　
　・環境
　　・Theanoインストール
　
実践チュートリアル はじめての画像認識
　・環境
　　・OpenCVインストール
　・画像認識とは
　　・画像認識(Image Recognintion）。
　　・画像認識は「コンピュータビジョン」の一部の分野。
　　・コンピュータビジョン（Computer vision）とは、コンピュータに画像や動画を入力して、必要な情報（顔認識や物体検知）を取り出す技術。
　　・コンピュータービジョンは、イベント検知や動画内の特定オブジェクトを追跡するビデオトラッキングなども含まれる。
　　・画像認識技術
　　　・自動画像整理機能
　　　　・「Enhanced Sharing」など。
　　　・画像検索
　　　　・「カーセンサー 中古車検索アプリ」など。
　　　・画像認識による医療診断
　　　　・「糖尿病性網膜症」の前兆検知など。
　　　・自動車安全装備
　　　　・画像認識プロセッサ「Viscontiシリーズ」など。

　・OpenCV 概要
　　・画像ライブラリ　「Pillow」、「OpenCV」、「Scikit-image」。
　　・OpenCVとは「Open Source Computer Vision Library」の略。日本語では「オープン・シー・ビー」。
　　・1999年から開始したプロジェクトで、インテルが開発・公開してオープンソース化
　　・画像処理、高度なパターン認識や物体検出、さらにk近傍法やSVMなどの機械学習手法も実装されている。
　　・rgb = cv2.imread('img_sample.jpg', 1)：画像読み込み
　　　・ファイルパス名、読み込み方法
　　　・読み込み方法
　　　　1：1 : 3チャンネルカラー画像（アルファチャンネルなし）
　　　　0 : グレースケール画像
　　　　-1 : 画像そのまま（アルファチャンネルあり）
　　　　アルファチャンネルとは各ピクセルに対して色表現とは別に画素の不透明度を表現したチャンネル.
　　　・画像データが何かしらの理由で読み込めない場合、NoneTypeを戻す。（ファイル無しなど）
　　　・imreadの対応しているフォーマット
　　　　・.bmp / .dib
　　　　・.jpeg / .jpg / .jpe
　　　　・.jp2
　　　　・.png
　　　　・.webp
　　　　・.pbm / .pgm / .ppm
　　　　・.sr / .ras
　　　　・.tiff / .tif
　　・logo = cv2.cvtColor(logo, cv2.COLOR_BGR2RGB)：GBR=>RGBに変換
　　・cat_blur1 = cv2.blur(cat, (5, 5))：ぼかし。ブラー。

　　・エッジ検出
　　　・エッジ検出（Edge Detection）
　　　・エッジ検出とは画像処理で使われる特徴抽出手法の一種。
　　　・画像の基本的な構造を概ね保持したまま処理するピクセル数を削減。
　　　・cat2_edge1 = cv2.Canny(cat2_rgb, 5, 50)：エッジ検出。

　　・画像の操作
　　　・cv2.imread()で読み込んだ画像データはNumpy配列。
　　　・スライシングやインデックス参照を使って、特定の箇所を抽出することが可能。
　　　・cat4_circle = cv2.circle(cat4_rgb, (240, 340), 50, color=(255, 0, 0), thickness=3)：画像に丸を追加。
　　　　・第一引数 : 画像
　　　　・第二引数 : 丸の中心
　　　　・第三引数 : 丸の半径
　　　　・第四引数 : 丸の色
　　　　・第五引数 : 丸の太さ
　　　・cat5_text = cv2.putText(cat5_rgb, "codexa", org=(300, 100), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=2,
                                color=(0, 150, 0), thickness=5)：画像にテキスト文字の追加

　・MNIST
　　・MNISTとはModified National Institute of Standards and Technology databaseの略。
　　・MNISTデータセット
　　　・画像データ 70,000画像
　　　・28 x 28のグレースケール画像
　　　・0〜9まで数字が手書きで描かれている
　　　・画像数字を示すラベルが付与されている
　　
　　・np.array(np.unique(y_train, return_counts=True)).astype(int)：ユニーク値の分布。
　
　機械学習で画像認識
　　・ロジスティック回帰
　　　・「分類問題に対する確率論的アプローチ」。
　　　・目標は、 サンプルが特定のカテゴリやクラスに属する「確率」をモデル化すること。
　　　・特徴
　　　　・シンプルな構造で推測結果の「説明」が比較的容易
　　　　・ハイパーパラメータチューニングが（ほぼ）不要
　　　　・線型性を仮定
　　・SVM（サポートベクターマシン）
　　　・サポートベクターマシン（Suport Vector Machine）
　　　・SVMは回帰・分類ともに行える。
　　　・特に分類の推測精度が高い。
　　　・カーネル法と呼ばれる手法が特徴的。
　　・ランダムフォレスト
　　　・「決定木」を複数使って「森」とする手法
　　　・複数の決定木モデルを構築して、それらを一つにまとめて、より正確かつ質の高い予測（分類）を行う手法
　　　・複数の弱いモデル（弱学習器）を一つにまとめる手法を「アンサンブル学習」と呼ぶ。
　　　・ランダムフォレストは「バギング」に属するアンサンブル学習の手法
　
　畳み込みニューラルネットワーク
　　・畳み込みニューラルネットワークは英語で「Convolutional Neural Network（読み：コンボリューショナル・ニューラル・ネットワーク）」
　　・CNNは画像データの数列から特定の形状を検出して、オブジェクトを認識して分類
　　・画像認識や画像オブジェクト検知など幅広い分野で活用される機械学習手法
　　・原型とも言われるのが「LeNet-5（レネット）」
　　・2012年に画像コンテストで圧倒的な推測精度を叩き出してAIブームの火付け役となったのは「AlexNet（アレックスネット）」
　　・CNNは下記の3つの構造からなる（前に入力層、最後に出力層）
　　　・畳み込み層(Convolution Layer)
　　　・プーリング層(Pooling Layer)
　　　・全結合層（Fully Connected Layer）
　　・入力層
　　　・CNNでは常に入力層から始まる
　　・畳み込み層
　　　・畳み込み層は入力された画像データの「特徴」を抽出する層
　　　・畳み込み層では入力層よりデータサイズが畳み込まれる（小さくなる）
　　　・元画像から「特徴」が抽出されたデータを特徴マップ（Feature Map）と呼ぶ
　　・プール層
　　　・畳み込み層で抽出された特徴マップを、より扱いやすくするため情報を圧縮
　　・全結合層
　　　・プール層で圧縮された特徴マップを平らにしてベクトルとして扱う（一次元にする）
　　　・出力層の手前で処理を行うことが多い
　　　・今ままでの処理で抽出された特徴の組み合わせから推測結果に分類するための処理を行う
　　　・一般的なニューラルネットワークの隠れ層と役目は一緒
　　　・特徴マップを平らにして重みを最適化
　　・出力層
　　　・活性化関数（例：シグモイド関数やソフトマックス関数）を使い、最終的な分類への出力を行う
　　　・出力層ではそれぞれのクラスに属する確率などをモデルの推測結果として出力する
　　
　　・畳み込み層
　　　・画像データから「特徴」を抽出するのが主な役割
　　　・「フィルタ（またはカーネル）」と呼ばれる小さい数列を適用して画像の特徴を抽出
　　　・元画像に対してフィルタが全てのピクセルにスライドするように処理を行う
　　　・入力画像とフィルタで内積をとる
　　　・特徴マップのサイズ
　　　　・入力数 - フィルタサイズ + 1（パディングサイズ考慮無し）
　　　・ストライドとはフィルタが「幾つスライドするかを指定する値」
　　　・「ゼロパディング（Zero Padding）」画像を取り囲むように0でパディングする
　　　・ストライドを、パディングを考慮した特徴マップサイズ
　　　　・元画像サイズ = ( h * W )、ストライド = S、パディング = P、フィルタサイズ = ( Fh, Fw )、出力サイズ = ( Oh * Ow)
　　　　・Oh = (h + 2P - Fh) / S + 1
　　　　・Ow = (W + 2P - Fw) / S + 1
　　　・畳み込み層で適用するフィルタの数は設計者（エンジニア）が決定
　　　・フィルタのパラメータを学習して調整。設計者が決める必要はない。
　　　・入力とフィルタで内積をとった値で活性化関数を通す
　　　・「ReLu」と呼ばれる活性化関数を使用するのが一般的（ReLuとはRectified Linear Unitの略）
　　　
　　・プール層
　　　・一般的なCNNでは畳み込み層の次にプール層の処理を行う
　　　・畳み込み層の特徴マップをさらに小さく圧縮させる処理を行う
　　　・プール層の目的
　　　　・計算コストを下げる
　　　　・過学習を防ぐ
　　　・圧縮方法
　　　　・Max Pooling
　　　　・Average Pooling
　　　　・Sum Pooling
　　　・一般的にはMax Poolingを使用
　　　・「プールサイズ」としてエンジニアが設定する
　　　
　　・全結合層
　　　・今まで処理を行ってきたユニットを全て「結合させる」層
　　　・出力層の手前で全結合層の処理を行う
　　　・最終的な推測を出力する前に、従来のニューラルネットワークのように全てのユニットを結合して重みを与えて最適化を行う
　　　・一般的なニューラルネットワークと同様に活性化関数を使用
　　
　　出力層
　　　・出力層では分類を行うクラスの数と一致している必要がある
　　　・出力層でも活性化関数を使用
　　　・分類クラスが3つ以上の場合はSoftmax関数
　　　・二項分類の場合、出力層は1となる場合はSigmoid関数
　
　CNNで画像認識
　　・Kerasには「channels_last（初期値）」と「channles_first」の2種類のデータフォーマットが用意されている
　　　・channels_last = (batch, height, width, channels)
　　　・channels_first= (batch, channels, height, width)
　　　・デフォルトはchannels_last
　　・ターゲットデータを、Kerasではクラスベクトルと呼ばれる、バイナリーのクラス行列へ変換する必要がある
　　・np_utils.to_categorical()：カテゴリカル変数、one-hotベクトルに変換
　　・model = Sequential()：モデルのインスタンス生成
　　・畳み込み層の追加
　　    model.add(Conv2D(8, kernel_size=(3, 3),  フィルタ数、フィルタサイズ
                 activation='relu',            活性化関数
                 input_shape=(28, 28, 1)))     入力形式
　　・プール層の追加
　　　  model.add(MaxPooling2D(pool_size=(2, 2)))  プーリングサイズ
　　・ドロップアウト
　　    model.add(Dropout(0.25)  ドロップアウトする割合
　　    一般的には0.25や0.5
　　・全結合層の追加
　　    model.add(Flatten())  １次元にする
　　    model.add(Dense(128, activation='relu'))  128ユニットの隠れ層
　　・出力層
　　    model.add(Dense(10, activation='softmax')) 10クラス分類、ソフトマックス
　　・model.summary()：モデルの構造確認
　　・model.compile(loss='categorical_crossentropy',  損失関数
              optimizer='sgd',  オプティマイザ
              metrics=['accuracy']) 精度
　　・損失関数（loss）
　　　・多項分類は「categorical_crossentropy」
　　　・二項分類の場合は「binary_crossentropy」
　　・最適化アルゴリズム（optimizer）
　　　・SGDとはStochastic Gradient Descentの略。確率的勾配降下法。
　　・model.fit(X_train, y_train, epochs=50)：モデルの訓練
　　・cnn_pred = model.predict(X_test)：予測
　　
　NDLラボ 平仮名画像データ
　　・「文字画像データセット（平仮名73文字版）」
　　・os.listdir(path)：ファイル、ディレクトリの一覧取得
　　・os.path.isfile()：ファイルかどうか
　　・os.isdir()：ディレクトリかどうか
　　・globモジュールはファイルやディレクトリを操作するときに、正規表現やワイルドカードによるパターンマッチングが可能
　　　・list1 = glob.glob("*.png")：拡張子を指定してファイルの一覧を取得
　　・files_df.sample(frac=1, random_state=42).reset_index(drop=True)：ランダムサンプリング
　　・np.save(path + 'charfeatures.npy', charfeatures)：numpy array をファイルに出力（バイナリファイル）
　　・charfeatures_load = np.load(path + 'charfeatures.npy')：ファイルから入力
　　・files_pd.to_csv(path + 'files_df.csv', index=False)：pandas DataFrame をファイルに出力
　　・files_df_load = pd.read_csv(path + 'files_df.csv')：ファイルから読み込み
　　・pd.value_counts()：各値ごとの数
　　・ターゲットクラスは平仮名の文字列のままでは、ニューラルネットワークの入力値として使用できない。
　　　LabelEncoder()を使って、それぞれの平仮名を数値へ変換する必要がある。
　　・encoder = LabelEncoder()：LabelEncoderインスタンス生成
　　・encoder.fit(y)：ターゲットデータのフィッティング
　　・encoder.classes_：認識したクラスの表示
　　・encoder.transform()：数値に変換
　　
　　・CNNで３つのモデルで試す
　　　・model_1
　　　　・ベースラインモデルとしてシンプルな構造のCNN
　　　　・畳み込み層x2、maxpooling層x2、全結合層x2
　　　・model_2
　　　　・model_1と同等の層を持つCNN
　　　　・model_1の各層にドロップアウト(0.25)を追加
　　　・model_3
　　　　・model_2をより深くした構造のCNN
　　　　・畳み込み層x3、maxpooling層x3、全結合層x2
　　・より正しい検証を行うためKerasのEarlyStoppingを用いる
　　・CNNのようなニューラルネットワークではモデル訓練が完了した時に最良とは限らない
　　・Kearsのコールバック（callbacks）を利用して、訓練中のモデル内部の状態と統計量を可視化することで、一定の条件を達した時点でモデル訓練を中断することが可能（EarlyStopping）
　　・callbacks = EarlyStopping(monitor='val_loss', patience=3)：EarlyStoppingを設定
　　　monitor='val_loss'　monitorとは訓練中に監視する値。validation data（テストデータ）のloss（損失関数の値）。
　　　patience=3　patienceは各エポックで値が改善しなくなってから訓練を中断するまでの回数。
　　・loss（損失関数の値）、acc（評価関数の値）は訓練データに対してのもの。
　　・val_lossとval_accはテストデータに対してのもの
　　・model_1.fit(X_train, y_train, validation_data=(X_test, y_tset), callbacks=[callbacks], epochs=50)：
　　　訓練。validation_data の loss で EarlyStopping。

　データ拡張
　　・データ拡張とは英語でData Augmentation
　　・データ拡張が必要なパターン
　　　・パターン1 不均衡データ
　　　　・「Garbage in, Garbage Out（ゴミを入れてもゴミしか出てこない）」と名言がある通り、データが非常に重要
　　　　・データに偏りがあることが多い
　　　　・データのクラスに偏りがあるデータを不均衡データ（Skewed Data）と呼ぶ
　　　　・病気を示すポジティブクラスの写真をより多く集められれば問題は解決する
　　　　・「稀な病気」だと、データを集めるのには多大な時間と労力がかかる
　　　　・現在あるデータを活用して、データを拡張することによりデータセット全体の不均衡性を解消することが可能
　　　・パターン2 推測精度を改善する
　　　　・モデルの推測精度を改善するためにも頻繁に用いられる
　　　　・原型を留めた形でデータを水増しする
　　　　
　データ読み込みと前処理
　　・データセット「Chest X-Ray Images(Pnuemonia)」
　　　・正常と肺炎の画像データ
　　　・コンテント　train, test, valごとにNormal, Pneumoniaに画像が分類
　　　　train
　　　　　- Normal 1,341枚
　　　　　- Pneumonia 3,875枚
　　　　test
　　　　　- Normal 234枚
　　　　　- Pneumonia 390枚
　　　　val
　　　　　- Normal 8枚
　　　　　- Pneumonia 8枚
　　　・フォーマット
　　　　jpeg形式
　　　　カラー
　　　　サイズ不均衡
　　　・備考
　　　　・「广州市?女儿童医?中心」の定期検診で取得されたデータ
　　　　・低品質のデータは事前にスクリーニングで除外
　　・img = cv2.resize(temp[i], (64, 64))：画像のリサイズ
　　・元画像に空白エリアを追加して、全ての画像を正方形にしてからリサイズする手法もある。
　　・異なるサイズのデータを扱えるようCNNの構造に工夫を加えることも可能
　　・np.where(train_df['Label'] == "PNEUMONIA", 1, 0)：条件に一致するデータのインデックスを取得。
　　　第２、第３引数がある場合は、一致する場合は第二引数、一致しない場合は第三引数を返す。
　　　
　ベースラインモデル訓練
　　・フィルタのサイズは数多くあるCNNのハイパーパラメータの一つ
　　　・(3, 3)で検証を行い、結果を確認しながら(5, 5)や(7, 7)と増やして検証するのが一般的
　　・プールサイズもCNNのハイパーパラメータの一つ
　　　・プール層のサイズは一般的に(2, 2)など偶数を用いる
　　　・プールサイズを大きくしてしまうと、より多くのデータが圧縮される
　　・ドロップアウトもCNNの重要なハイパーパラメータ
　　　・一般的に(0.25)や(0.5)が使われる
　　　・値が高すぎると未学習になる
　　・「肺炎(1)」「正常(0)」の二項分類なので、出力層の活性化関数は「Sigmoid（シグモイド）」
　　・二項分類は「Sigmoid（シグモイド）」、「Sigmoid（シグモイド）」を使用
　　・「elu（Exponential Linear unit）」や「tanh（ハイパボリックタンジェント）」がある
　　・二項分類なので損失関数は「binary_crossentropy」
　　・最適化関数は「Adam（読み：アダム）」を使用
　　・「Adam」は確率的勾配降下法（Stochastic Gradient Descent）の拡張版
　　・CNNの最適化関数は「Adam」または「SGD（確率的勾配降下法）」を利用するのが一般的
　
　データ拡張
　　・Kerasでは、「ImageDataGenerator」クラスでデータ拡張できる
　　　・rotation_range : 範囲内にランダムで回転
　　　・width_shift_range ： 範囲内でランダムに水平シフト
　　　・height_shift_range : 範囲内でランダムに垂直シフト
　　　・shear_range : 指定した角度でせん断変換
　　　・zoom_range : 範囲内でランダムにズーム
　　　・horizontal_flip : ランダムに水平方向に反転
　　　・data_gen = ImageDataGenerator(　　：加工した画像を作成のインスタンス
    rotation_range=50,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.2,
    zoom_range=0.1,
    horizontal_flip=True
)
　　　・datagen.flow()：加工した画像の取得
　　　・datagen.flow()は加工処理を加えたデータをバッチで戻す
　　　・ジェネレーターを使ったモデル訓練はfit_generator()を使う
　　　・steps_per_epochは1回のエポックのジェネレーターの合計yield数を指定
　　　・指定がない場合はlen(generator)で算出
　　　・aug_model.fit_generator(　　ジェネレーターを使ったモデル訓練
    data_gen.flow(X_train, y_train, batch_size=32, seed=42),
    steps_per_epoch=163,
    epochs=20,
    verbose=1,
    shuffle=False,
    callbacks=[callbacks],
    validation_data=(X_test, y_test)
)

その他
　・np.count_nonzero(y_train == 0)：条件に一致するものをカウント
　・keras.backend.image_data_format()：データフォーマット確認　「channels_last（初期値）」と「channles_first」
　・assert ：条件を満たさない場合に例外を発生させる
　
